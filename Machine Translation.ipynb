{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-VWgfK8psyL"
   },
   "source": [
    "# **Machine Translation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gcYHgUId0u0"
   },
   "source": [
    "## **Translating from French to Fongbe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUUf8kVBeHtE"
   },
   "source": [
    "### This project seeks to create a machine translation system from French to Fonge and from French to Ewe.\n",
    "\n",
    "> A Machine translation (MT) is an automatic translation from one language to another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O60bQ-EepsyP"
   },
   "outputs": [],
   "source": [
    "## importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXCwbKkAefe-"
   },
   "source": [
    "#### **Data Loading and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "pULY5t5kpsyR",
    "outputId": "7c0722ee-fcb0-4b72-a38d-e7d7bd5d2bf3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target_Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AAAAhgRX</td>\n",
       "      <td>Très fière d’elle</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AAGuzGzi</td>\n",
       "      <td>Tous ces grands artistes viendront au Benin po...</td>\n",
       "      <td>Fon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AAuiTPkQ</td>\n",
       "      <td>Ce programme va travailler à améliorer les con...</td>\n",
       "      <td>Fon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_ACYgGXTq</td>\n",
       "      <td>Quels sont les questions récurrentes de ceux ...</td>\n",
       "      <td>Fon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AChdWHyF</td>\n",
       "      <td>Grosse bagnolle</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  ... Target_Language\n",
       "0  ID_AAAAhgRX  ...             Ewe\n",
       "1  ID_AAGuzGzi  ...             Fon\n",
       "2  ID_AAuiTPkQ  ...             Fon\n",
       "3  ID_ACYgGXTq  ...             Fon\n",
       "4  ID_AChdWHyF  ...             Ewe\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv('AITest.csv')\n",
    "train=pd.read_csv('AITrain.csv')\n",
    "submission=pd.read_csv('AISampleSubmission (1).csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "5Sc4OklmpsyS",
    "outputId": "7e8df36a-7024-444e-8e10-fa2f8f0e0b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75487, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target_Language</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AADNDxdl</td>\n",
       "      <td>Mon père</td>\n",
       "      <td>Fon</td>\n",
       "      <td>Tɔ ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AAFQhmDr</td>\n",
       "      <td>Mettez-vous en rang.</td>\n",
       "      <td>Fon</td>\n",
       "      <td>Mi tò miɖéé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AAHVDMdq</td>\n",
       "      <td>Sénégal, Côte d'Ivoire, Guinée, Ghana, on déco...</td>\n",
       "      <td>Ewe</td>\n",
       "      <td>Sénégal, Côte d'Ivoire, Guinée, Ghana, siwo ƒe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AAJfVHEH</td>\n",
       "      <td>Son doigt lui fait mal.</td>\n",
       "      <td>Fon</td>\n",
       "      <td>Alɔvi tɔn ɖo vivɛ wɛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AAOJuhzN</td>\n",
       "      <td>La pluie a commencé.</td>\n",
       "      <td>Fon</td>\n",
       "      <td>Jì bɛ́</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  ...                                             Target\n",
       "0  ID_AADNDxdl  ...                                              Tɔ ce\n",
       "1  ID_AAFQhmDr  ...                                        Mi tò miɖéé\n",
       "2  ID_AAHVDMdq  ...  Sénégal, Côte d'Ivoire, Guinée, Ghana, siwo ƒe...\n",
       "3  ID_AAJfVHEH  ...                               Alɔvi tɔn ɖo vivɛ wɛ\n",
       "4  ID_AAOJuhzN  ...                                             Jì bɛ́\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPFrZC1ceoun"
   },
   "source": [
    "We have a total of 75487 training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ESeDioDspsyV"
   },
   "outputs": [],
   "source": [
    "## Cleaning Data\n",
    "train['French']=train['French'].apply(lambda x: x.lower())\n",
    "train['French']=train['French'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "exclude = set(string.punctuation) \n",
    "train['French']=train['French'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "train['French']=train['French'].apply(lambda x: x.translate(remove_digits))\n",
    "train['French']=train['French'].apply(lambda x: x.strip())\n",
    "train['French']=train['French'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlO6IiwCe-tw"
   },
   "source": [
    "# **FON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0RD9EVhspqaM"
   },
   "outputs": [],
   "source": [
    "## We take out Fon and work with it first.\n",
    "train_fon=train[train['Target_Language']=='Fon']\n",
    "train_fon.drop('Target_Language',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HqAe31TJgx0I"
   },
   "outputs": [],
   "source": [
    "#Adding start and end tokens\n",
    "train_fon['Target'] = train_fon['Target'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JCrNRiRPpsyY"
   },
   "outputs": [],
   "source": [
    "### Get English and Fon Vocabulary\n",
    "french_vocab=set()\n",
    "for french_words in train_fon['French']:\n",
    "    for word in french_words.split():\n",
    "        if word not in french_vocab:\n",
    "            french_vocab.add(word)\n",
    "\n",
    "fon_vocab=set()\n",
    "for fon_words in train_fon['Target']:\n",
    "    for word in fon_words.split():\n",
    "        if word not in fon_vocab:\n",
    "            fon_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oPRRuroKpsyZ"
   },
   "outputs": [],
   "source": [
    "# fon_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "klab_gvepsyZ"
   },
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "train_fon['length_french_sentence']=train_fon['French'].apply(lambda x:len(x.split(\" \")))\n",
    "train_fon['length_fon_sentence']=train_fon['Target'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MB8yEk7dpsya",
    "outputId": "e37da25a-8ae3-4e6d-dd8a-aaf8c9b26e64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 52)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_tar=max(train_fon[\"length_fon_sentence\"])\n",
    "max_length_src=max(train_fon[\"length_french_sentence\"])\n",
    "max_length_tar,max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqW3_xA4hI_o",
    "outputId": "40b668a9-03c3-43d9-acd5-d958d8de2c9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fon[train_fon['length_fon_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "5j0n3cp9psyZ",
    "outputId": "94108e72-55ca-4577-b04a-0f8314c3f1ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target</th>\n",
       "      <th>length_french_sentence</th>\n",
       "      <th>length_fon_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AADNDxdl</td>\n",
       "      <td>mon père</td>\n",
       "      <td>START_ Tɔ ce _END</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AAFQhmDr</td>\n",
       "      <td>mettezvous en rang</td>\n",
       "      <td>START_ Mi tò miɖéé _END</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AAJfVHEH</td>\n",
       "      <td>son doigt lui fait mal</td>\n",
       "      <td>START_ Alɔvi tɔn ɖo vivɛ wɛ _END</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AAOJuhzN</td>\n",
       "      <td>la pluie a commencé</td>\n",
       "      <td>START_ Jì bɛ́ _END</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_AAOZhyDe</td>\n",
       "      <td>les garçons et les filles sont au cours élémen...</td>\n",
       "      <td>START_ Nyɔnu lε kpo sunnu lε kpo ɖo wemaxomε a...</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  ... length_fon_sentence\n",
       "0  ID_AADNDxdl  ...                   4\n",
       "1  ID_AAFQhmDr  ...                   5\n",
       "3  ID_AAJfVHEH  ...                   7\n",
       "4  ID_AAOJuhzN  ...                   4\n",
       "5  ID_AAOZhyDe  ...                  14\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "X56awojsu-Ih"
   },
   "outputs": [],
   "source": [
    "#We take sentences with length less than or equal to 20.\n",
    "train_fon=train_fon[train_fon['length_fon_sentence']<=20]\n",
    "train_fon=train_fon[train_fon['length_french_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ8TalhdssSm",
    "outputId": "2d818a89-1442-4646-961f-2e14afdadcb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12842, 15520)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We create encoder and decoder tokens\n",
    "input_words = sorted(list(french_vocab))\n",
    "target_words = sorted(list(fon_vocab))\n",
    "num_encoder_tokens = len(french_vocab)\n",
    "num_decoder_tokens = len(fon_vocab)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WHdoy514psya"
   },
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n",
    "num_encoder_tokens+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iL6sRVlHpsyb"
   },
   "outputs": [],
   "source": [
    "#Create index for the tokens\n",
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tK_xLnQ2psyb"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "NcEsnohFtYOg",
    "outputId": "0d1bc32a-d6b0-447e-ca1e-674138d300c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target</th>\n",
       "      <th>length_french_sentence</th>\n",
       "      <th>length_fon_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6772</th>\n",
       "      <td>ID_EiTelMfr</td>\n",
       "      <td>fais donc ainsi</td>\n",
       "      <td>START_ Bo bló lĕe _END</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66013</th>\n",
       "      <td>ID_taOUEVMh</td>\n",
       "      <td>cet enfant a une grosse bouche tombante</td>\n",
       "      <td>START_ Vi elɔ ɖo nu gɛjɛɛ _END</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17346</th>\n",
       "      <td>ID_LyORKIaq</td>\n",
       "      <td>alors jallais à pied</td>\n",
       "      <td>START_ Un ɖo yiyi wɛ kpodo afɔ kpo ɖayi _END</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29641</th>\n",
       "      <td>ID_UUmwFxjk</td>\n",
       "      <td>ce qu’il a dit m’a bouleversé</td>\n",
       "      <td>START_ Xó é ɖɔ́ ɔ́ é zɛ̀ hùn nú mì _END</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31493</th>\n",
       "      <td>ID_VjeicDYB</td>\n",
       "      <td>il fait des éclairs</td>\n",
       "      <td>START_ Xɛbyoso kɛ wùn _END</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  ... length_fon_sentence\n",
       "6772   ID_EiTelMfr  ...                   5\n",
       "66013  ID_taOUEVMh  ...                   7\n",
       "17346  ID_LyORKIaq  ...                  10\n",
       "29641  ID_UUmwFxjk  ...                  11\n",
       "31493  ID_VjeicDYB  ...                   5\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fon=shuffle(train_fon)#Shuffle the data\n",
    "train_fon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oo0USNePpsyc",
    "outputId": "80b957b0-fe79-402d-ea42-b5a46cb375b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41958,), (10490,))"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Splitting the Data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = train_fon['French'], train_fon['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0WgrzLh5psyd"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "f33Airg8psyd"
   },
   "outputs": [],
   "source": [
    "latent_dim=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "EZwgjwCHpsye"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "f89pFvG-psye"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byS_OtJgpsyf",
    "outputId": "3ad53eec-528b-450e-c54f-09e201b6a139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     642150      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     776050      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 15521)  791571      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,250,171\n",
      "Trainable params: 2,250,171\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Qg6qqxoZpsyf"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 8\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEpFOS0Dpsyh",
    "outputId": "431d2367-f63f-43b9-c619-4ca6a984ad19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5244/5244 [==============================] - 261s 45ms/step - loss: 0.5805 - val_loss: 0.5136\n",
      "Epoch 2/20\n",
      "5244/5244 [==============================] - 235s 45ms/step - loss: 0.5044 - val_loss: 0.4905\n",
      "Epoch 3/20\n",
      "5244/5244 [==============================] - 234s 45ms/step - loss: 0.4896 - val_loss: 0.4976\n",
      "Epoch 4/20\n",
      "5244/5244 [==============================] - 234s 45ms/step - loss: 0.4972 - val_loss: 0.5037\n",
      "Epoch 5/20\n",
      "5244/5244 [==============================] - 231s 44ms/step - loss: 0.4955 - val_loss: 0.4958\n",
      "Epoch 6/20\n",
      "5244/5244 [==============================] - 231s 44ms/step - loss: 0.4851 - val_loss: 0.4867\n",
      "Epoch 7/20\n",
      "5244/5244 [==============================] - 231s 44ms/step - loss: 0.4733 - val_loss: 0.4792\n",
      "Epoch 8/20\n",
      "5244/5244 [==============================] - 231s 44ms/step - loss: 0.4626 - val_loss: 0.4727\n",
      "Epoch 9/20\n",
      "5244/5244 [==============================] - 230s 44ms/step - loss: 0.4533 - val_loss: 0.4671\n",
      "Epoch 10/20\n",
      "5244/5244 [==============================] - 228s 44ms/step - loss: 0.4447 - val_loss: 0.4608\n",
      "Epoch 11/20\n",
      "5244/5244 [==============================] - 229s 44ms/step - loss: 0.4353 - val_loss: 0.4568\n",
      "Epoch 12/20\n",
      "5244/5244 [==============================] - 229s 44ms/step - loss: 0.4271 - val_loss: 0.4549\n",
      "Epoch 13/20\n",
      "5244/5244 [==============================] - 228s 43ms/step - loss: 0.4203 - val_loss: 0.4507\n",
      "Epoch 14/20\n",
      "5244/5244 [==============================] - 228s 43ms/step - loss: 0.4138 - val_loss: 0.4501\n",
      "Epoch 15/20\n",
      "5244/5244 [==============================] - 229s 44ms/step - loss: 0.4065 - val_loss: 0.4484\n",
      "Epoch 16/20\n",
      "5244/5244 [==============================] - 228s 43ms/step - loss: 0.3997 - val_loss: 0.4401\n",
      "Epoch 17/20\n",
      "5244/5244 [==============================] - 227s 43ms/step - loss: 0.3906 - val_loss: 0.4365\n",
      "Epoch 18/20\n",
      "5244/5244 [==============================] - 228s 43ms/step - loss: 0.3840 - val_loss: 0.4333\n",
      "Epoch 19/20\n",
      "5244/5244 [==============================] - 227s 43ms/step - loss: 0.3807 - val_loss: 0.4344\n",
      "Epoch 20/20\n",
      "5244/5244 [==============================] - 228s 43ms/step - loss: 0.3747 - val_loss: 0.4292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3977cfdc50>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Q7_3wvuJ16Fl"
   },
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights_fongbe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyvDh-Hapovk"
   },
   "outputs": [],
   "source": [
    "# model.load_weights('nmt_weights_fongbe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ek3DImSJRw-m"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) #embeddings of the decoder sequence\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Jhc-F4HcR5Os"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "   \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtACxu4bnulK"
   },
   "source": [
    "## **Prediction on Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "gmAFgl-iR_Mm"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_test, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDKhRdwOSE9P",
    "outputId": "3d44ae7f-9d55-4fa0-a32e-25af5a76195c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input French sentence: il coupe l’herbe\n",
      "Predicted Fon Translation:  Un ná sɔ́ ɖó \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input French sentence:', X_train[k:k+1].values[0])\n",
    "print('Predicted Fon Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFLKSessM2Af"
   },
   "source": [
    "## **Ewe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ZdwQEKrphtDC",
    "outputId": "7af94504-f68e-47e1-e923-3a5979f282f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AAHVDMdq</td>\n",
       "      <td>sénégal côte divoire guinée ghana on découvre ...</td>\n",
       "      <td>Sénégal, Côte d'Ivoire, Guinée, Ghana, siwo ƒe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_AARXSjjg</td>\n",
       "      <td>janot se prit à grelotter dès que le soleil se...</td>\n",
       "      <td>Yano dze ƒoƒo esi me ɣe gbe ɖo to eye ya dze ƒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID_AAmSrrNh</td>\n",
       "      <td>et cela en une journée sinon rien à manger</td>\n",
       "      <td>Nawɔe le ŋkekea me. Nemenyυo oa, atdi adɔ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ID_AAsKjVJM</td>\n",
       "      <td>l’idée est partie de deux incidents survenus l...</td>\n",
       "      <td>nua dze eg,ome tso masɔmasɔ aɖe siwo do mo ɖa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ID_ABAUPxlf</td>\n",
       "      <td>mais je souris quand même parce que ça fait pa...</td>\n",
       "      <td>kehã meko nu elabe esia hã le dɔa wɔwɔ me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ...                                             Target\n",
       "2   ID_AAHVDMdq  ...  Sénégal, Côte d'Ivoire, Guinée, Ghana, siwo ƒe...\n",
       "6   ID_AARXSjjg  ...  Yano dze ƒoƒo esi me ɣe gbe ɖo to eye ya dze ƒ...\n",
       "13  ID_AAmSrrNh  ...          Nawɔe le ŋkekea me. Nemenyυo oa, atdi adɔ\n",
       "17  ID_AAsKjVJM  ...  nua dze eg,ome tso masɔmasɔ aɖe siwo do mo ɖa ...\n",
       "19  ID_ABAUPxlf  ...        kehã meko nu elabe esia hã le dɔa wɔwɔ me\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['French']=train['French'].apply(lambda x: x.lower())\n",
    "train['French']=train['French'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "exclude = set(string.punctuation) \n",
    "train['French']=train['French'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "train['French']=train['French'].apply(lambda x: x.translate(remove_digits))\n",
    "train['French']=train['French'].apply(lambda x: x.strip())\n",
    "train['French']=train['French'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "\n",
    "\n",
    "train_ewe=train[train['Target_Language']=='Ewe']\n",
    "train_ewe.drop('Target_Language',inplace=True,axis=1)\n",
    "train_ewe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "qDcSpYRSc20_",
    "outputId": "b4658ec1-33a5-4b61-8a2f-c75f739c8e3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AAHVDMdq</td>\n",
       "      <td>sénégal côte divoire guinée ghana on découvre ...</td>\n",
       "      <td>START_ Sénégal, Côte d'Ivoire, Guinée, Ghana, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_AARXSjjg</td>\n",
       "      <td>janot se prit à grelotter dès que le soleil se...</td>\n",
       "      <td>START_ Yano dze ƒoƒo esi me ɣe gbe ɖo to eye y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID_AAmSrrNh</td>\n",
       "      <td>et cela en une journée sinon rien à manger</td>\n",
       "      <td>START_ Nawɔe le ŋkekea me. Nemenyυo oa, atdi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ID_AAsKjVJM</td>\n",
       "      <td>l’idée est partie de deux incidents survenus l...</td>\n",
       "      <td>START_ nua dze eg,ome tso masɔmasɔ aɖe siwo do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ID_ABAUPxlf</td>\n",
       "      <td>mais je souris quand même parce que ça fait pa...</td>\n",
       "      <td>START_ kehã meko nu elabe esia hã le dɔa wɔw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ...                                             Target\n",
       "2   ID_AAHVDMdq  ...  START_ Sénégal, Côte d'Ivoire, Guinée, Ghana, ...\n",
       "6   ID_AARXSjjg  ...  START_ Yano dze ƒoƒo esi me ɣe gbe ɖo to eye y...\n",
       "13  ID_AAmSrrNh  ...  START_ Nawɔe le ŋkekea me. Nemenyυo oa, atdi a...\n",
       "17  ID_AAsKjVJM  ...  START_ nua dze eg,ome tso masɔmasɔ aɖe siwo do...\n",
       "19  ID_ABAUPxlf  ...  START_ kehã meko nu elabe esia hã le dɔa wɔw...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ewe['Target'] = train_ewe['Target'].apply(lambda x : 'START_ '+ x + ' _END')\n",
    "train_ewe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--NcdQ5DcueJ"
   },
   "outputs": [],
   "source": [
    "### Get English and Ewe Vocabulary\n",
    "french_vocab=set()\n",
    "for french_words in train_ewe['French']:\n",
    "    for word in french_words.split():\n",
    "        if word not in french_vocab:\n",
    "            french_vocab.add(word)\n",
    "\n",
    "ewe_vocab=set()\n",
    "for ewe_words in train_ewe['Target']:\n",
    "    for word in ewe_words.split():\n",
    "        if word not in ewe_vocab:\n",
    "            ewe_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "GDaS3aCscpwH",
    "outputId": "72a0bd6d-01a7-4443-bcac-02c983a497d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target</th>\n",
       "      <th>length_french_sentence</th>\n",
       "      <th>length_ewe_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AAHVDMdq</td>\n",
       "      <td>sénégal côte divoire guinée ghana on découvre ...</td>\n",
       "      <td>START_ Sénégal, Côte d'Ivoire, Guinée, Ghana, ...</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_AARXSjjg</td>\n",
       "      <td>janot se prit à grelotter dès que le soleil se...</td>\n",
       "      <td>START_ Yano dze ƒoƒo esi me ɣe gbe ɖo to eye y...</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID_AAmSrrNh</td>\n",
       "      <td>et cela en une journée sinon rien à manger</td>\n",
       "      <td>START_ Nawɔe le ŋkekea me. Nemenyυo oa, atdi a...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ID_AAsKjVJM</td>\n",
       "      <td>l’idée est partie de deux incidents survenus l...</td>\n",
       "      <td>START_ nua dze eg,ome tso masɔmasɔ aɖe siwo do...</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ID_ABAUPxlf</td>\n",
       "      <td>mais je souris quand même parce que ça fait pa...</td>\n",
       "      <td>START_ kehã meko nu elabe esia hã le dɔa wɔw...</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ... length_ewe_sentence\n",
       "2   ID_AAHVDMdq  ...                  18\n",
       "6   ID_AARXSjjg  ...                  21\n",
       "13  ID_AAmSrrNh  ...                  10\n",
       "17  ID_AAsKjVJM  ...                  21\n",
       "19  ID_ABAUPxlf  ...                  12\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ewe['length_french_sentence']=train_ewe['French'].apply(lambda x:len(x.split(\" \")))\n",
    "train_ewe['length_ewe_sentence']=train_ewe['Target'].apply(lambda x:len(x.split(\" \")))\n",
    "train_ewe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHGjMr1kedfI",
    "outputId": "169240d7-b6a9-4eb5-ee42-7fb95c0186fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 69)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_tar=max(train_ewe[\"length_ewe_sentence\"])\n",
    "max_length_src=max(train_ewe[\"length_french_sentence\"])\n",
    "max_length_src,max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzGsyD7QeMYE",
    "outputId": "d17a93eb-cd72-4236-92fc-dbdc928ac123"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30142, 30180)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ewe=train_ewe[train_ewe['length_ewe_sentence']<=30]\n",
    "train_ewe=train_ewe[train_ewe['length_french_sentence']<=30]\n",
    "\n",
    "\n",
    "\n",
    "input_words = sorted(list(french_vocab))\n",
    "target_words = sorted(list(ewe_vocab))\n",
    "num_encoder_tokens = len(french_vocab)\n",
    "num_decoder_tokens = len(ewe_vocab)\n",
    "num_encoder_tokens, num_decoder_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rJn5Pxkfc_N"
   },
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n",
    "# num_encoder_tokens+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Dcu5K-RhckB0",
    "outputId": "8cf84f7c-cac3-4566-d8e3-9a961f4e0386"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target</th>\n",
       "      <th>length_french_sentence</th>\n",
       "      <th>length_ewe_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57700</th>\n",
       "      <td>ID_njkyALVW</td>\n",
       "      <td>et encore…il y a également beaucoup de noms qu...</td>\n",
       "      <td>START_ eye ŋkɔ geɖewo hã li siwoe fluaa ame _END</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65877</th>\n",
       "      <td>ID_tVlRdnDX</td>\n",
       "      <td>et je lui ferai rendre ma rivière</td>\n",
       "      <td>START_ Eye mana woa trɔ nye tɔsisia nam _END</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62748</th>\n",
       "      <td>ID_rLYozhHO</td>\n",
       "      <td>com la pauvreté est la principale cause de la ...</td>\n",
       "      <td>START_ ahedada enye zãnuɖuɖu suetɔ ƒe dzotsoƒ...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37182</th>\n",
       "      <td>ID_ZXdXJeIU</td>\n",
       "      <td>il ne reviendra plus à moins qu’il décide fini...</td>\n",
       "      <td>START_ wobe magagbnɔ gbeɖe o ne mele didim be ...</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69473</th>\n",
       "      <td>ID_vqjYFwtY</td>\n",
       "      <td>ces trois religions semblaient très distinctes...</td>\n",
       "      <td>START_ xɔseha etɔ̃ siawo dze abe woto vovo neg...</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  ... length_ewe_sentence\n",
       "57700  ID_njkyALVW  ...                  10\n",
       "65877  ID_tVlRdnDX  ...                   9\n",
       "62748  ID_rLYozhHO  ...                   8\n",
       "37182  ID_ZXdXJeIU  ...                  16\n",
       "69473  ID_vqjYFwtY  ...                  20\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "\n",
    "\n",
    "train_ewe=shuffle(train_ewe)\n",
    "train_ewe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8cBNGxXeymf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = train_ewe['French'], train_ewe['Target']\n",
    "X_train_ewe, X_test_ewe, y_train_ewe, y_test_ewe = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train_ewe.shape, X_test_ewe.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bznwOwtc_zz"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train_ewe, y = y_train_ewe, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:                        \n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrKdVJJTfrNj",
    "outputId": "ce616fbe-7506-4858-edbc-e54793e486bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     1507100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     1509050     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 30181)  1539231     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,595,781\n",
      "Trainable params: 4,595,781\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim=50\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOdDdQsWYCOW"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train_ewe)\n",
    "val_samples = len(X_test_ewe)\n",
    "batch_size = 8\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9zmaE1McaB5",
    "outputId": "122ec921-de32-4c54-ea17-22be201eca5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2079/2079 [==============================] - 861s 403ms/step - loss: 1.2933 - val_loss: 1.1953\n",
      "Epoch 2/20\n",
      "2079/2079 [==============================] - 830s 399ms/step - loss: 1.1860 - val_loss: 1.1734\n",
      "Epoch 3/20\n",
      "2079/2079 [==============================] - 818s 394ms/step - loss: 1.1541 - val_loss: 1.1647\n",
      "Epoch 4/20\n",
      "2079/2079 [==============================] - 823s 396ms/step - loss: 1.1284 - val_loss: 1.1570\n",
      "Epoch 5/20\n",
      "2079/2079 [==============================] - 843s 406ms/step - loss: 1.1100 - val_loss: 1.1541\n",
      "Epoch 6/20\n",
      "2079/2079 [==============================] - 825s 397ms/step - loss: 1.0958 - val_loss: 1.1570\n",
      "Epoch 7/20\n",
      "2079/2079 [==============================] - 821s 395ms/step - loss: 1.0928 - val_loss: 1.1937\n",
      "Epoch 8/20\n",
      "2079/2079 [==============================] - 823s 396ms/step - loss: 1.0966 - val_loss: 1.1735\n",
      "Epoch 9/20\n",
      "2079/2079 [==============================] - 824s 397ms/step - loss: 1.0884 - val_loss: 1.1909\n",
      "Epoch 10/20\n",
      "2079/2079 [==============================] - 822s 395ms/step - loss: 1.0969 - val_loss: 1.2095\n",
      "Epoch 11/20\n",
      "2079/2079 [==============================] - 815s 392ms/step - loss: 1.1068 - val_loss: 1.2225\n",
      "Epoch 12/20\n",
      "2079/2079 [==============================] - 811s 390ms/step - loss: 1.1114 - val_loss: 1.2332\n",
      "Epoch 13/20\n",
      "2079/2079 [==============================] - 818s 394ms/step - loss: 1.1119 - val_loss: 1.2349\n",
      "Epoch 14/20\n",
      "2079/2079 [==============================] - 816s 392ms/step - loss: 1.1073 - val_loss: 1.2354\n",
      "Epoch 15/20\n",
      "2079/2079 [==============================] - 825s 397ms/step - loss: 1.1003 - val_loss: 1.2388\n",
      "Epoch 16/20\n",
      "2079/2079 [==============================] - 822s 395ms/step - loss: 1.0902 - val_loss: 1.2388\n",
      "Epoch 17/20\n",
      "2079/2079 [==============================] - 818s 393ms/step - loss: 1.0786 - val_loss: 1.2467\n",
      "Epoch 18/20\n",
      "2079/2079 [==============================] - 828s 398ms/step - loss: 1.0723 - val_loss: 1.2480\n",
      "Epoch 19/20\n",
      "2079/2079 [==============================] - 822s 396ms/step - loss: 1.0646 - val_loss: 1.2505\n",
      "Epoch 20/20\n",
      "2079/2079 [==============================] - 814s 391ms/step - loss: 1.0583 - val_loss: 1.2571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8127715a50>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train_ewe, y_train_ewe, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test_ewe, y_test_ewe, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8X_K1EphY7k"
   },
   "outputs": [],
   "source": [
    "##We save the weights so that we can use them later\n",
    "model.save_weights('nmt_weights2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7LiKV0yw3Tf"
   },
   "outputs": [],
   "source": [
    "#We load the weights\n",
    "# model.load_weights('nmt_weights2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9x-18hytdJAC"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_pfEpyboBYh"
   },
   "source": [
    "## **Prediction on Train Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiTYbjK3n_s_"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_gen = generate_batch(X_train_ewe, y_train_ewe, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "on-knKnnfZJm",
    "outputId": "de0d6152-c613-4105-c74d-0f816fed64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input French sentence: dans une interview au daily express des aliments l’expert a indiqué que changer ses habitudes alimentaires en prenant un avocat par jour permettrait de lutter contre la chute des cheveux\n",
      "Actual Ewe Translation:  le nyanyanana aɖe si wona Dayli express la, egblɔ be peyaɖuɖu gbe sia gbe la nana wotoa ɖa \n",
      "Predicted Ewe Translation:  le na la na be la, ame siwo wole ƒe be la le eƒe\n"
     ]
    }
   ],
   "source": [
    "#predict on the train set\n",
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input French sentence:', X_train_ewe[k:k+1].values[0])\n",
    "print('Actual Ewe Translation:', y_train_ewe[k:k+1].values[0][6:-4])\n",
    "print('Predicted Ewe Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oJ1nkPLnfrY"
   },
   "source": [
    "The model was able to get some words right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hS69JB51B4W"
   },
   "source": [
    "## **Translation to Ewe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "RB4Mc2ZDfwjl",
    "outputId": "5515435a-77ec-41e1-8108-cc04a80bfe70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target_Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AAAAhgRX</td>\n",
       "      <td>Très fière d’elle</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AAGuzGzi</td>\n",
       "      <td>Tous ces grands artistes viendront au Benin po...</td>\n",
       "      <td>Fon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AAuiTPkQ</td>\n",
       "      <td>Ce programme va travailler à améliorer les con...</td>\n",
       "      <td>Fon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_ACYgGXTq</td>\n",
       "      <td>Quels sont les questions récurrentes de ceux ...</td>\n",
       "      <td>Fon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AChdWHyF</td>\n",
       "      <td>Grosse bagnolle</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  ... Target_Language\n",
       "0  ID_AAAAhgRX  ...             Ewe\n",
       "1  ID_AAGuzGzi  ...             Fon\n",
       "2  ID_AAuiTPkQ  ...             Fon\n",
       "3  ID_ACYgGXTq  ...             Fon\n",
       "4  ID_AChdWHyF  ...             Ewe\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieIODOr3hnRV"
   },
   "outputs": [],
   "source": [
    "#Getting Ewe from the test data\n",
    "test_ewe=test[test['Target_Language']=='Ewe']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "FMQfI0KtiIc7",
    "outputId": "f7e9060d-6cd7-40e0-e516-4030bccdeb6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target_Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AAAAhgRX</td>\n",
       "      <td>Très fière d’elle</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AChdWHyF</td>\n",
       "      <td>Grosse bagnolle</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ID_AHBSoUNL</td>\n",
       "      <td>Les seins comme ça… » Basta</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ID_AHycIkQv</td>\n",
       "      <td>Lire aussi Pensées Nocturnes</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ID_AIWTdKBT</td>\n",
       "      <td>voir même de la positivité, de la gaieté et po...</td>\n",
       "      <td>Ewe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ... Target_Language\n",
       "0   ID_AAAAhgRX  ...             Ewe\n",
       "4   ID_AChdWHyF  ...             Ewe\n",
       "11  ID_AHBSoUNL  ...             Ewe\n",
       "14  ID_AHycIkQv  ...             Ewe\n",
       "16  ID_AIWTdKBT  ...             Ewe\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ewe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPXwIxlXh58a",
    "outputId": "d0696765-fdfd-4e7c-dad4-4c8b6fb70037"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2964, 2929)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ewe),len(test_fon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPSkHyuLgtUD"
   },
   "outputs": [],
   "source": [
    "translated_text=[]\n",
    "french_language=[]\n",
    "for i in range(len(test_ewe['French'])):\n",
    "  k+=1\n",
    "  (input_seq, actual_output), _ = next(train_gen)\n",
    "  decoded_sentence= decode_sequence(input_seq)\n",
    "  french_sent=test_ewe.French[k:k+1].values[0]\n",
    "  translation=decoded_sentence[:-4]\n",
    "  french_language.append(french_sent)\n",
    "  translated_text.append(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "olXLF2JF7HFL",
    "outputId": "a60d6968-d2f7-41ac-cc6d-c68b0002c38e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target_Language</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AAAAhgRX</td>\n",
       "      <td>Très fière d’elle</td>\n",
       "      <td>Ewe</td>\n",
       "      <td>nye be nye me le wo nu sia me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AChdWHyF</td>\n",
       "      <td>Grosse bagnolle</td>\n",
       "      <td>Ewe</td>\n",
       "      <td>la le esi menɔ esi menɔ esi menɔ me o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ID_AHBSoUNL</td>\n",
       "      <td>Les seins comme ça… » Basta</td>\n",
       "      <td>Ewe</td>\n",
       "      <td>ele be nu si le eƒe me be nye la le eƒe gbe me ɖ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ID_AHycIkQv</td>\n",
       "      <td>Lire aussi Pensées Nocturnes</td>\n",
       "      <td>Ewe</td>\n",
       "      <td>nye le eƒe me la ame o eye be ame siwo wole la w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ID_AIWTdKBT</td>\n",
       "      <td>voir même de la positivité, de la gaieté et po...</td>\n",
       "      <td>Ewe</td>\n",
       "      <td>esi nye be be ame aɖe si le eƒe le eƒe me be l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ...                                             Target\n",
       "0   ID_AAAAhgRX  ...                     nye be nye me le wo nu sia me \n",
       "4   ID_AChdWHyF  ...             la le esi menɔ esi menɔ esi menɔ me o \n",
       "11  ID_AHBSoUNL  ...   ele be nu si le eƒe me be nye la le eƒe gbe me ɖ\n",
       "14  ID_AHycIkQv  ...   nye le eƒe me la ame o eye be ame siwo wole la w\n",
       "16  ID_AIWTdKBT  ...     esi nye be be ame aɖe si le eƒe le eƒe me be l\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ewe['Target']=translated_text\n",
    "test_ewe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "AB3JffhT7QnM",
    "outputId": "7c9e43e6-f539-4bf4-f8af-faa055048bc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>French</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AAAAhgRX</td>\n",
       "      <td>Très fière d’elle</td>\n",
       "      <td>nye be nye me le wo nu sia me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AChdWHyF</td>\n",
       "      <td>Grosse bagnolle</td>\n",
       "      <td>la le esi menɔ esi menɔ esi menɔ me o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ID_AHBSoUNL</td>\n",
       "      <td>Les seins comme ça… » Basta</td>\n",
       "      <td>ele be nu si le eƒe me be nye la le eƒe gbe me ɖ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ID_AHycIkQv</td>\n",
       "      <td>Lire aussi Pensées Nocturnes</td>\n",
       "      <td>nye le eƒe me la ame o eye be ame siwo wole la w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ID_AIWTdKBT</td>\n",
       "      <td>voir même de la positivité, de la gaieté et po...</td>\n",
       "      <td>esi nye be be ame aɖe si le eƒe le eƒe me be l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ...                                             Target\n",
       "0   ID_AAAAhgRX  ...                     nye be nye me le wo nu sia me \n",
       "4   ID_AChdWHyF  ...             la le esi menɔ esi menɔ esi menɔ me o \n",
       "11  ID_AHBSoUNL  ...   ele be nu si le eƒe me be nye la le eƒe gbe me ɖ\n",
       "14  ID_AHycIkQv  ...   nye le eƒe me la ame o eye be ame siwo wole la w\n",
       "16  ID_AIWTdKBT  ...     esi nye be be ame aɖe si le eƒe le eƒe me be l\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ewe.drop(['Target_Language'],inplace=True,axis=1)\n",
    "test_ewe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM1hDVVh6xtY",
    "outputId": "10f6aef9-8c84-4551-c793-4acfd37a6a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2964, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_ewe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdpYOTMZhgJq"
   },
   "outputs": [],
   "source": [
    "test_ewe[[\"ID\",\"Target\"]].to_csv(\"ewe1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CL65KRaVoZhg"
   },
   "source": [
    "## **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc885qLBoeY0"
   },
   "source": [
    "\n",
    ">References:https://www.kaggle.com/aiswaryaramachandran/english-to-hindi-neural-machine-translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HbFzNR-7vDV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Group1_MachineTranslation_NLP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
